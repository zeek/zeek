module RESP;

import Redis;

import spicy;

# Maximum size for parsing of certain fields. By restricting this we avoid
# exhausting main memory.
const MAX_SIZE = 1024 * 1024;

public type Messages = unit {
    : (Data &synchronize)[];
};

public type ClientMessages = unit {
    : (ClientData &synchronize)[];
};

public type ServerMessages = unit {
    : (ServerData &synchronize)[];
};

public type ClientData = unit {
    %synchronize-after = b"\x0d\x0a";
    # Clients can only be an array or inline
    ty: uint8 &convert=DataType($$);
    if (self.ty == DataType::ARRAY) {
        multibulk: Array;
    } else {
        # HACK: If the type isn'tan array, this is just some random unserialized
        # string until \r\n - do this by prepending the type to the remaining bytes.
        # Formally in Redis code, that's an "inline command."
        #
        # As an extra point, this is handled in redis in `processInlineBuffer`,
        # which has a hardcoded limit of 1024*64. That seems too big. We'll do 1024.
        inline: RedisBytes &convert=(pack(cast<uint8>(self.ty), spicy::ByteOrder::Network) + $$) &max-size=1024;
    };

    var command: Redis::Command;

    on %done {
        self.command = Redis::make_command(self);
    }
};

public type ServerData = unit {
    %synchronize-after = b"\x0d\x0a";
    data: Data;
};

public type Data = unit {
    %synchronize-after = b"\x0d\x0a";
    ty: uint8 &convert=DataType($$);
    switch (self.ty) {
        DataType::SIMPLE_STRING -> simple_string: SimpleString(False);
        DataType::SIMPLE_ERROR -> simple_error: SimpleString(True);
        DataType::INTEGER -> integer: Integer;
        DataType::BULK_STRING -> bulk_string: BulkString(False);
        DataType::ARRAY -> array: Array;
        DataType::NULL -> null: Null_;
        DataType::BOOLEAN -> boolean: Boolean;
        DataType::DOUBLE -> double: Double;
        DataType::BIG_NUM -> big_num: BigNum;
        DataType::BULK_ERROR -> bulk_error: BulkString(True);
        # This can be a different type, but the docs also say:
        # "Some client libraries may ignore the difference between this type and the string type"
        # It just includes the encoding first in the content
        DataType::VERBATIM_STRING -> verbatim_string: BulkString(False);
        DataType::MAP -> map_: Map;
        DataType::SET -> set_: Set;
        # "Push events are encoded similarly to arrays, differing only in their
        # first byte" - TODO: can probably make it more obvious, though
        DataType::PUSH -> push: Array;
    };
};

type DataType = enum {
    SIMPLE_STRING = '+',
    SIMPLE_ERROR = '-',
    INTEGER = ':',
    BULK_STRING = '$',
    ARRAY = '*',
    NULL = '_',
    BOOLEAN = '#',
    DOUBLE = ',',
    BIG_NUM = '(',
    BULK_ERROR = '!',
    VERBATIM_STRING = '=',
    MAP = '%',
    SET = '~',
    PUSH = '>',
};

# Helper unit to extract bytes of some reasonable size so we do not exhaust mem.
type RedisBytes = unit {
    data: bytes &until=b"\x0d\x0a" &max-size=MAX_SIZE;
} &convert=self.data;

type SimpleString = unit(is_error: bool) {
    content: RedisBytes;
};

type Integer = unit {
    int: RedisBytes &convert=$$.to_int(10);
};

type BulkString = unit(is_error: bool) {
    length: RedisBytes &convert=$$.to_int(10) &requires=self.length <= int64(MAX_SIZE);
    # NullBulkString is a BulkString with content unset
    content: bytes &size=uint64(self.length) if(self.length >= 0);

    # Consume last CLRF
    : skip RedisBytes;
};

type Array = unit {
    num_elements: RedisBytes &convert=$$.to_int(10) &requires=self.num_elements <= int64(MAX_SIZE);
    # Null array is an array with elements unset. This is different from an empty array
    elements: Data[uint64(self.num_elements)];
};

type Null_ = unit {
    # Still must consume CLRF
    : skip RedisBytes;
};

type Boolean = unit {
    val: uint8 &convert=$$ == 't';
    : skip RedisBytes;
};

type Double = unit {
    val: RedisBytes &convert=$$.to_real();
};

type BigNum = unit {
    # Big num can be very big so leave it in bytes.
    val: RedisBytes;
};

type Map = unit {
    var key_val_pairs: vector<tuple<Data, Data>>;
    num_elements: RedisBytes &convert=$$.to_uint(10);
    # TODO: How can I make this into a map? Alternatively, how can I do this better?
    raw_data: Data[self.num_elements * 2] {
        while (local i = 0; i < self.num_elements) {
            self.key_val_pairs.push_back(($$[i], $$[i + 1]));
            i += 2;
        }
    }
};

type Set = unit {
    num_elements: RedisBytes &convert=$$.to_uint(10) &requires=self.num_elements <= MAX_SIZE;
    # TODO: This should be a set but doesn't go in the backed C++ set
    elements: Data[self.num_elements];
};

on Data::%done {
    spicy::accept_input();
}

on Data::%error {
    spicy::decline_input("error while parsing RESP data");
}
